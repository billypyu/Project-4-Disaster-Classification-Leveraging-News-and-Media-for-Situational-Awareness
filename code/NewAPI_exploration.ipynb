{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mission: To webscrap news articles from a variety of sources\n",
    "\n",
    "- Use news API to identify interesting articles\n",
    "- Build scrapping code to scrape the articles from the source provided by the news API\n",
    "- Store the news articles in a permanent database\n",
    "- Process the text of the articles in preparation for NLP\n",
    "- Build interesting models around the text to understand sentiment\n",
    "\n",
    "API source: https://newsapi.org/docs/endpoints/everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import date\n",
    "import requests\n",
    "import time\n",
    "now = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_news (search_terms,file_name, n_pagesize, start_page, end_pages, save_to_csv): \n",
    "    '''\n",
    "    term_request = which is the key word for search.\n",
    "    save_to_csv = True indicates csv will be saved\n",
    "    '''\n",
    "    \n",
    "    # API requests\n",
    "    for term in search_terms: \n",
    "        url = 'https://newsapi.org/v2/everything?'\n",
    "        \n",
    "        param = {\n",
    "    #'country' : 'us',\n",
    "    'q': term,  #search term \n",
    "    'apiKey' : 'e685d6e1420f4882b86d029ed3c1a11d',\n",
    "    'pageSize': n_pagesize, #max page\n",
    "    'language': 'en'}\n",
    "        print (term)\n",
    "        \n",
    "        every_term = requests.get(url, params = param)\n",
    "        #every_term.json()['articles']\n",
    "        #every_term.json().keys()\n",
    "        #print (every_term)\n",
    "\n",
    "    articles = every_term.json()['articles'] \n",
    "    \n",
    "    for page in range(start_page, end_pages): #go throught 10 times, and get more pages, 10 more pages\n",
    "        param['page'] = page\n",
    "        \n",
    "        more_term = requests.get(url, params = param)\n",
    "        more_term = more_term.json()['articles']\n",
    "        \n",
    "        #print(len(more_term))\n",
    "        articles.extend(more_term)\n",
    "    arts = pd.DataFrame(articles)\n",
    "    \n",
    "    # Drop null and duplicate \n",
    "    arts.dropna(inplace=True)\n",
    "    arts.drop_duplicates(subset='content',inplace = True)\n",
    "    \n",
    "    # Create columns\n",
    "    arts['source_id'] = arts['source'].map(lambda x: x['id'])\n",
    "    arts['source_name'] = arts['source'].map(lambda x: x['name']) #break up the source, source id, and name colums seperate\n",
    "    arts.drop (columns = ['source'], axis=1)\n",
    "    arts['yes_disaster'] = 1\n",
    "\n",
    "    # Save df to csv\n",
    "    if save_to_csv == True: \n",
    "        arts.to_csv('../data/'+str(file_name)+'_'+str(now) +'.csv' ,index = False, sep = \",\") #index = False for no extra columns\n",
    "        print (f'{len(articles)} unique news haved been saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disaster\n",
      "20 unique news haved been saved\n"
     ]
    }
   ],
   "source": [
    "#call the function \n",
    "save_news (['disaster'], file_name ='b', n_pagesize=10, start_page=2, end_pages=3, save_to_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/b_1554939746.6693828.csv\n",
      "../data/b_1554940839.5361001.csv\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "path = \"../data/*.csv\"\n",
    "for fname in glob.glob(path):\n",
    "    print (fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>description</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>source_name</th>\n",
       "      <th>yes_disaster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nick Douglas</td>\n",
       "      <td>If I was setting up curriculum at a university...</td>\n",
       "      <td>“If I was setting up curriculum at a universit...</td>\n",
       "      <td>2019-02-21T18:00:00Z</td>\n",
       "      <td>How Tiny Mistakes Cause Huge Disasters</td>\n",
       "      <td>https://lifehacker.com/how-tiny-mistakes-cause...</td>\n",
       "      <td>Lifehacker.com</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Megan Rose Dickey</td>\n",
       "      <td>The lack of diversity issue in Silicon Valley ...</td>\n",
       "      <td>The lack of diversity issue in Silicon Valley ...</td>\n",
       "      <td>2018-07-30T17:21:57Z</td>\n",
       "      <td>Venture capital’s diversity disaster</td>\n",
       "      <td>http://techcrunch.com/2018/07/30/venture-capit...</td>\n",
       "      <td>TechCrunch</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Devin Coldewey</td>\n",
       "      <td>One would think that having one of the most hi...</td>\n",
       "      <td>One would think that having one of the most hi...</td>\n",
       "      <td>2019-03-08T20:32:24Z</td>\n",
       "      <td>MyEquifax.com is yet another security disaster</td>\n",
       "      <td>http://techcrunch.com/2019/03/08/myequifax-com...</td>\n",
       "      <td>TechCrunch</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Matt Simon</td>\n",
       "      <td>California continues to take stock of its unpr...</td>\n",
       "      <td>The rains are coming to California, and the fi...</td>\n",
       "      <td>2018-11-20T11:00:00Z</td>\n",
       "      <td>California Fire Survivors Brace for Debris-Fil...</td>\n",
       "      <td>https://www.wired.com/story/california-fire-su...</td>\n",
       "      <td>Wired</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nick Douglas</td>\n",
       "      <td>Does the Sydney Opera House really exist outsi...</td>\n",
       "      <td>Does the Sydney Opera House really exist outsi...</td>\n",
       "      <td>2018-05-14T13:00:00Z</td>\n",
       "      <td>Tell Us Your Sydney, Australia Travel Tips</td>\n",
       "      <td>https://lifehacker.com/tell-us-your-sydney-aus...</td>\n",
       "      <td>Lifehacker.com</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              author                                            content  \\\n",
       "0       Nick Douglas  If I was setting up curriculum at a university...   \n",
       "1  Megan Rose Dickey  The lack of diversity issue in Silicon Valley ...   \n",
       "2     Devin Coldewey  One would think that having one of the most hi...   \n",
       "3         Matt Simon  California continues to take stock of its unpr...   \n",
       "4       Nick Douglas  Does the Sydney Opera House really exist outsi...   \n",
       "\n",
       "                                         description           publishedAt  \\\n",
       "0  “If I was setting up curriculum at a universit...  2019-02-21T18:00:00Z   \n",
       "1  The lack of diversity issue in Silicon Valley ...  2018-07-30T17:21:57Z   \n",
       "2  One would think that having one of the most hi...  2019-03-08T20:32:24Z   \n",
       "3  The rains are coming to California, and the fi...  2018-11-20T11:00:00Z   \n",
       "4  Does the Sydney Opera House really exist outsi...  2018-05-14T13:00:00Z   \n",
       "\n",
       "                                               title  \\\n",
       "0             How Tiny Mistakes Cause Huge Disasters   \n",
       "1               Venture capital’s diversity disaster   \n",
       "2     MyEquifax.com is yet another security disaster   \n",
       "3  California Fire Survivors Brace for Debris-Fil...   \n",
       "4         Tell Us Your Sydney, Australia Travel Tips   \n",
       "\n",
       "                                                 url     source_name  \\\n",
       "0  https://lifehacker.com/how-tiny-mistakes-cause...  Lifehacker.com   \n",
       "1  http://techcrunch.com/2018/07/30/venture-capit...      TechCrunch   \n",
       "2  http://techcrunch.com/2019/03/08/myequifax-com...      TechCrunch   \n",
       "3  https://www.wired.com/story/california-fire-su...           Wired   \n",
       "4  https://lifehacker.com/tell-us-your-sydney-aus...  Lifehacker.com   \n",
       "\n",
       "   yes_disaster  \n",
       "0             1  \n",
       "1             1  \n",
       "2             1  \n",
       "3             1  \n",
       "4             1  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('../data/b_1554939746.6693828.csv')\n",
    "df = df.drop(['source','urlToImage','source_id'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi]",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
