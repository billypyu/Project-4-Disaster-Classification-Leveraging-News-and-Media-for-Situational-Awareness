{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mission: To webscrap news articles from a variety of sources\n",
    "\n",
    "- Use news API to identify interesting articles\n",
    "- Build scrapping code to scrape the articles from the source provided by the news API\n",
    "- Store the news articles in a permanent database\n",
    "- Process the text of the articles in preparation for NLP\n",
    "- Build interesting models around the text to understand sentiment\n",
    "\n",
    "API source: https://newsapi.org/docs/endpoints/everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from datetime import date\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_news (search_terms, n_pagesize, n_pages, save_to_csv): \n",
    "    '''\n",
    "    term_request = which is the key word for search.\n",
    "    save_to_csv = True indicates csv will be saved\n",
    "    '''\n",
    "    \n",
    "    # API requests\n",
    "    for term in search_terms: \n",
    "        url = 'https://newsapi.org/v2/everything?'\n",
    "        \n",
    "        param = {\n",
    "    #'country' : 'us',\n",
    "    'q': term,  #search term \n",
    "    'apiKey' : 'e685d6e1420f4882b86d029ed3c1a11d',\n",
    "    'pageSize': n_pagesize, #max page\n",
    "    'language': 'en'}\n",
    "        print (term)\n",
    "        \n",
    "        every_term = requests.get(url, params = param)\n",
    "        #every_term.json()['articles']\n",
    "        #every_term.json().keys()\n",
    "        #print (every_term)\n",
    "\n",
    "    articles = every_term.json()['articles'] \n",
    "    \n",
    "    for page in range(2, n_pages): #go throught 10 times, and get more pages, 10 more pages\n",
    "        #print('page: ' + str(page))\n",
    "        param['page'] = page\n",
    "        \n",
    "        more_term = requests.get(url, params = param)\n",
    "        more_term = more_term.json()['articles']\n",
    "        \n",
    "        #print(len(more_term))\n",
    "        articles.extend(more_term)\n",
    "    arts = pd.DataFrame(articles)\n",
    "    \n",
    "    # Drop null and duplicate \n",
    "    arts.dropna(inplace=True)\n",
    "    arts.drop_duplicates(subset='content',inplace = True)\n",
    "    \n",
    "    # Create columns\n",
    "    arts['source_id'] = arts['source'].map(lambda x: x['id'])\n",
    "    arts['source_name'] = arts['source'].map(lambda x: x['name']) #break up the source, source id, and name colums seperate\n",
    "    \n",
    "    # Save df to csv\n",
    "    if save_to_csv == True: \n",
    "        arts.to_csv('../data/'+ str(date.today())+'.csv' ,index = False, sep = \",\") #index = False for no extra columns\n",
    "        print (f'{len(articles)} unique news haved been saved')\n",
    "    \n",
    "    # Review df \n",
    "    return arts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# news = ['disaster', 'crisis']\n",
    "# for new in ['disaster', 'crisis']: \n",
    "#     save_news (new, n_pagesize=10, n_pages=3, save_to_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "earthquake\n",
      "Tornado\n",
      "20 unique news haved been saved\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>description</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>urlToImage</th>\n",
       "      <th>source_id</th>\n",
       "      <th>source_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Patrick Allan</td>\n",
       "      <td>Every year, around 1,200 tornadoes hit the Uni...</td>\n",
       "      <td>Every year, around 1,200 tornadoes hit the Uni...</td>\n",
       "      <td>2018-05-07T21:00:00Z</td>\n",
       "      <td>{'id': None, 'name': 'Lifehacker.com'}</td>\n",
       "      <td>How to Stay Safe During a Tornado</td>\n",
       "      <td>https://lifehacker.com/how-to-stay-safe-during...</td>\n",
       "      <td>https://i.kinja-img.com/gawker-media/image/upl...</td>\n",
       "      <td>None</td>\n",
       "      <td>Lifehacker.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Patrick Allan</td>\n",
       "      <td>You see those green, billowing storm clouds ov...</td>\n",
       "      <td>You see those green, billowing storm clouds ov...</td>\n",
       "      <td>2018-03-29T21:00:00Z</td>\n",
       "      <td>{'id': None, 'name': 'Lifehacker.com'}</td>\n",
       "      <td>If You See Green Storm Clouds, Prepare for the...</td>\n",
       "      <td>https://lifehacker.com/if-you-see-green-storm-...</td>\n",
       "      <td>https://i.kinja-img.com/gawker-media/image/upl...</td>\n",
       "      <td>None</td>\n",
       "      <td>Lifehacker.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Maddie Stone on Earther, shared by Andrew Cout...</td>\n",
       "      <td>Weather geeks went wild last week when the Nat...</td>\n",
       "      <td>Weather geeks went wild last week when the Nat...</td>\n",
       "      <td>2018-08-09T13:33:00Z</td>\n",
       "      <td>{'id': None, 'name': 'Gizmodo.com'}</td>\n",
       "      <td>California's Viral Fire Tornado Has Scientists...</td>\n",
       "      <td>https://earther.gizmodo.com/californias-viral-...</td>\n",
       "      <td>https://i.kinja-img.com/gawker-media/image/upl...</td>\n",
       "      <td>None</td>\n",
       "      <td>Gizmodo.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Laura Vitto</td>\n",
       "      <td>Harrowing new footage released by California's...</td>\n",
       "      <td>Harrowing new footage released by California's...</td>\n",
       "      <td>2018-08-18T15:11:00Z</td>\n",
       "      <td>{'id': 'mashable', 'name': 'Mashable'}</td>\n",
       "      <td>Deadly, 40,000-foot fire tornado revealed in n...</td>\n",
       "      <td>https://mashable.com/2018/08/18/fire-tornado-c...</td>\n",
       "      <td>https://i.amz.mshcdn.com/wGGKuJnaCby3RdJJ-sdWp...</td>\n",
       "      <td>mashable</td>\n",
       "      <td>Mashable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ALAN BLINDER</td>\n",
       "      <td>The presidents trip came three days after he a...</td>\n",
       "      <td>President Trump’s visit to Beauregard, Ala., c...</td>\n",
       "      <td>2019-03-08T20:08:42Z</td>\n",
       "      <td>{'id': 'the-new-york-times', 'name': 'The New ...</td>\n",
       "      <td>Trump Surveys Tornado Damage in Alabama</td>\n",
       "      <td>https://www.nytimes.com/2019/03/08/us/trump-al...</td>\n",
       "      <td>https://static01.nyt.com/images/2019/03/08/us/...</td>\n",
       "      <td>the-new-york-times</td>\n",
       "      <td>The New York Times</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              author  \\\n",
       "0                                      Patrick Allan   \n",
       "1                                      Patrick Allan   \n",
       "2  Maddie Stone on Earther, shared by Andrew Cout...   \n",
       "3                                        Laura Vitto   \n",
       "5                                       ALAN BLINDER   \n",
       "\n",
       "                                             content  \\\n",
       "0  Every year, around 1,200 tornadoes hit the Uni...   \n",
       "1  You see those green, billowing storm clouds ov...   \n",
       "2  Weather geeks went wild last week when the Nat...   \n",
       "3  Harrowing new footage released by California's...   \n",
       "5  The presidents trip came three days after he a...   \n",
       "\n",
       "                                         description           publishedAt  \\\n",
       "0  Every year, around 1,200 tornadoes hit the Uni...  2018-05-07T21:00:00Z   \n",
       "1  You see those green, billowing storm clouds ov...  2018-03-29T21:00:00Z   \n",
       "2  Weather geeks went wild last week when the Nat...  2018-08-09T13:33:00Z   \n",
       "3  Harrowing new footage released by California's...  2018-08-18T15:11:00Z   \n",
       "5  President Trump’s visit to Beauregard, Ala., c...  2019-03-08T20:08:42Z   \n",
       "\n",
       "                                              source  \\\n",
       "0             {'id': None, 'name': 'Lifehacker.com'}   \n",
       "1             {'id': None, 'name': 'Lifehacker.com'}   \n",
       "2                {'id': None, 'name': 'Gizmodo.com'}   \n",
       "3             {'id': 'mashable', 'name': 'Mashable'}   \n",
       "5  {'id': 'the-new-york-times', 'name': 'The New ...   \n",
       "\n",
       "                                               title  \\\n",
       "0                  How to Stay Safe During a Tornado   \n",
       "1  If You See Green Storm Clouds, Prepare for the...   \n",
       "2  California's Viral Fire Tornado Has Scientists...   \n",
       "3  Deadly, 40,000-foot fire tornado revealed in n...   \n",
       "5            Trump Surveys Tornado Damage in Alabama   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://lifehacker.com/how-to-stay-safe-during...   \n",
       "1  https://lifehacker.com/if-you-see-green-storm-...   \n",
       "2  https://earther.gizmodo.com/californias-viral-...   \n",
       "3  https://mashable.com/2018/08/18/fire-tornado-c...   \n",
       "5  https://www.nytimes.com/2019/03/08/us/trump-al...   \n",
       "\n",
       "                                          urlToImage           source_id  \\\n",
       "0  https://i.kinja-img.com/gawker-media/image/upl...                None   \n",
       "1  https://i.kinja-img.com/gawker-media/image/upl...                None   \n",
       "2  https://i.kinja-img.com/gawker-media/image/upl...                None   \n",
       "3  https://i.amz.mshcdn.com/wGGKuJnaCby3RdJJ-sdWp...            mashable   \n",
       "5  https://static01.nyt.com/images/2019/03/08/us/...  the-new-york-times   \n",
       "\n",
       "          source_name  \n",
       "0      Lifehacker.com  \n",
       "1      Lifehacker.com  \n",
       "2         Gizmodo.com  \n",
       "3            Mashable  \n",
       "5  The New York Times  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_news (['earthquake','Tornado'], n_pagesize=10, n_pages=3, save_to_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigate the headlines endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://newsapi.org/v2/top-headlines?'\n",
    "\n",
    "param = {\n",
    "    'country' : 'us',\n",
    "    'category': 'business', #top headline and everthing cater\n",
    "    'apiKey' : 'e685d6e1420f4882b86d029ed3c1a11d',\n",
    "    'pageSize': 100,\n",
    "}\n",
    "\n",
    "business_headlines = requests.get(url, params = param)\n",
    "business_headlines = business_headlines.json()\n",
    "business_headlines.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#business_headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#business_headlines.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['status', 'totalResults', 'articles'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#business_headlines['articles'] #where these articles come from "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigate the sources endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://newsapi.org/v2/sources?'\n",
    "\n",
    "param = {\n",
    "    'country' : 'us',\n",
    "    'q': 'earthquake',\n",
    "    #'category': 'business',\n",
    "    'apiKey' : 'e685d6e1420f4882b86d029ed3c1a11d',\n",
    "    'pageSize': 100,\n",
    "}\n",
    "\n",
    "earthquake_sources = requests.get(url, params = param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#earthquake_sources.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "now = time.time()\n",
    "#str(now)\n",
    "\n",
    "\n",
    "# now = str(now) #Unknown format code 'f' for object of type 'str'\n",
    "\n",
    "#create the time stampe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "arts.to_csv(f'./earthquake_{now:.0f}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schedule automated tasks with Cron\n",
    "\n",
    "Next let's setup a python script to automatically collect data everyday. We can do this with cron. \n",
    "\n",
    "Here are a couple great resources you might reference as we go through cron:   \n",
    "https://www.taniarascia.com/setting-up-a-basic-cron-job-in-linux/  \n",
    "https://ole.michelsen.dk/blog/schedule-jobs-with-crontab-on-mac-osx.html  \n",
    "\n",
    "#### What is cron? \n",
    "\n",
    "Cron is a scheduler that allows a user to automate certain functionality to run at specific times. The way timing is encoded in cron is a bit arcane. \n",
    "\n",
    "Let's check out this site and try to understand how it works: https://crontab.guru/#0_0_*_*_*\n",
    "\n",
    "Crontab have 5 * to indicate delineations in time. \n",
    "\n",
    "For example, \n",
    "\n",
    "\\* \\* \\* \\* \\*\n",
    "\n",
    "equates to every minute, every hour, every day, every month, and every day of the week  \n",
    "\n",
    "This can be a bit confusing. I suggest that when you want to setup a crontab for a specific time, you play around with the crontab.guru and try to get it to output the timing you want. Let's try to get a cron schedule for once a day at noon. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "each markdown has meaning . * is any. 1 is mintues, second is hour, 3rd is day of the month, 4 is month, 5 is the day of the week"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
