{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DOC2VEC Tryout "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This file is a tryout of Word2vec method. Code Reference : \n",
    "    - https://towardsdatascience.com/multi-class-text-classification-with-doc2vec-logistic-regression-9da9947b43f4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#DOC2VEC-Tryout\" data-toc-modified-id=\"DOC2VEC-Tryout-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>DOC2VEC Tryout</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#This-file-is-a-tryout-of-Word2vec-method.-Code-Reference-:\" data-toc-modified-id=\"This-file-is-a-tryout-of-Word2vec-method.-Code-Reference-:-1.0.1\"><span class=\"toc-item-num\">1.0.1&nbsp;&nbsp;</span>This file is a tryout of Word2vec method. Code Reference :</a></span></li></ul></li><li><span><a href=\"#1.-Clean-Up-Datafame\" data-toc-modified-id=\"1.-Clean-Up-Datafame-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>1. Clean Up Datafame</a></span><ul class=\"toc-item\"><li><span><a href=\"#Examing-Content\" data-toc-modified-id=\"Examing-Content-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Examing Content</a></span></li></ul></li><li><span><a href=\"#Text-Processing\" data-toc-modified-id=\"Text-Processing-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Text Processing</a></span></li><li><span><a href=\"#Regular-Train-Test-Split\" data-toc-modified-id=\"Regular-Train-Test-Split-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Regular Train Test Split</a></span><ul class=\"toc-item\"><li><span><a href=\"#Set-up-Doc2Vec-Training-with-Stopwords\" data-toc-modified-id=\"Set-up-Doc2Vec-Training-with-Stopwords-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Set-up Doc2Vec Training with Stopwords</a></span></li><li><span><a href=\"#Evaluation-Models\" data-toc-modified-id=\"Evaluation-Models-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Evaluation Models</a></span></li></ul></li><li><span><a href=\"#Set-up-Doc2Vec-Training-with-Stopwords-and-Time-series-Train-Test-Split\" data-toc-modified-id=\"Set-up-Doc2Vec-Training-with-Stopwords-and-Time-series-Train-Test-Split-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Set-up Doc2Vec Training with Stopwords and Time-series Train Test Split</a></span><ul class=\"toc-item\"><li><span><a href=\"#Evaluation-Models-with-Time-series-train-test-split\" data-toc-modified-id=\"Evaluation-Models-with-Time-series-train-test-split-1.4.1\"><span class=\"toc-item-num\">1.4.1&nbsp;&nbsp;</span>Evaluation Models with Time-series train test split</a></span></li><li><span><a href=\"#GridSearch-for-the-hyperparameter-for-KNN-and-Logistic-Regression\" data-toc-modified-id=\"GridSearch-for-the-hyperparameter-for-KNN-and-Logistic-Regression-1.4.2\"><span class=\"toc-item-num\">1.4.2&nbsp;&nbsp;</span>GridSearch for the hyperparameter for KNN and Logistic Regression</a></span></li></ul></li><li><span><a href=\"#Gridsearch-to-find-the-best-parameters\" data-toc-modified-id=\"Gridsearch-to-find-the-best-parameters-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Gridsearch to find the best parameters</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "from gensim.models import Doc2Vec\n",
    "from sklearn import utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gensim\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import regex as re\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "from datetime import date\n",
    "import time\n",
    "now = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, VotingClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "from pactools.grid_search import GridSearchCVProgressBar\n",
    "\n",
    "from sklearn.pipeline import Pipeline \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Clean Up Datafame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in dataframe \n",
    "df = pd.read_csv('../data/df_balanced_consolidated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df): \n",
    "    index_1 = df[df['publishedAt'].isnull()].index\n",
    "    \n",
    "    df = df.drop(index_1)\n",
    "    df.reset_index(inplace = True, drop= True)\n",
    "    \n",
    "    boolian = []\n",
    "    for i in range(len(df['publishedAt'])):\n",
    "        boolian.append(df['publishedAt'][i][0] != '2')\n",
    "    \n",
    "    df = df.drop(df[boolian].index)\n",
    "    df.reset_index(inplace = True, drop= True)\n",
    "    \n",
    "    df['date'] = df['publishedAt'].apply(lambda x: str(x).split('T')[0])\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df = df.set_index(df['date'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>description</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>source</th>\n",
       "      <th>source_id</th>\n",
       "      <th>source_name</th>\n",
       "      <th>title</th>\n",
       "      <th>types</th>\n",
       "      <th>url</th>\n",
       "      <th>urlToImage</th>\n",
       "      <th>yes_disaster</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-04</th>\n",
       "      <td>https://www.facebook.com/bbcnews</td>\n",
       "      <td>image copyrightepaimage caption  tens of thous...</td>\n",
       "      <td>Storm Pabuk has made landfall in southern Thai...</td>\n",
       "      <td>2019-01-04T07:28:56Z</td>\n",
       "      <td>{'id': 'bbc-news', 'name': 'BBC News'}</td>\n",
       "      <td>bbc-news</td>\n",
       "      <td>BBC News</td>\n",
       "      <td>Thailand Pabuk: Tourist spots hit by worst sto...</td>\n",
       "      <td>landfall</td>\n",
       "      <td>https://www.bbc.co.uk/news/world-asia-46756239</td>\n",
       "      <td>https://ichef.bbci.co.uk/news/1024/branded_new...</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-11</th>\n",
       "      <td>NEETI UPADHYE</td>\n",
       "      <td>1 u s  paul manaforts trail of scandals</td>\n",
       "      <td>Hurricane Michael made landfall in Florida at ...</td>\n",
       "      <td>2018-10-11T16:18:46Z</td>\n",
       "      <td>{'id': 'the-new-york-times', 'name': 'The New ...</td>\n",
       "      <td>the-new-york-times</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>‘Trees Flying By’: The Aftermath of Hurricane ...</td>\n",
       "      <td>landfall</td>\n",
       "      <td>https://www.nytimes.com/video/us/politics/1000...</td>\n",
       "      <td>https://static01.nyt.com/images/2018/10/12/us/...</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-10-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-12</th>\n",
       "      <td>Dell Cameron</td>\n",
       "      <td>the federal communications commission on frida...</td>\n",
       "      <td>The Federal Communications Commission on Frida...</td>\n",
       "      <td>2018-10-12T22:25:00Z</td>\n",
       "      <td>{'id': None, 'name': 'Gizmodo.com'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gizmodo.com</td>\n",
       "      <td>Widespread Cable, Internet, and Radio Outages ...</td>\n",
       "      <td>landfall</td>\n",
       "      <td>https://gizmodo.com/widespread-cable-internet-...</td>\n",
       "      <td>https://i.kinja-img.com/gawker-media/image/upl...</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-10-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-05</th>\n",
       "      <td>Reuters Editorial</td>\n",
       "      <td>reuters  - tropical storm gordon was making l...</td>\n",
       "      <td>Tropical storm Gordon was making landfall just...</td>\n",
       "      <td>2018-09-05T03:12:45Z</td>\n",
       "      <td>{'id': 'reuters', 'name': 'Reuters'}</td>\n",
       "      <td>reuters</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>Storm Gordon making landfall west of Alabama-M...</td>\n",
       "      <td>landfall</td>\n",
       "      <td>https://www.reuters.com/article/us-storm-gordo...</td>\n",
       "      <td>https://s4.reutersmedia.net/resources_v2/image...</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-09-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-04</th>\n",
       "      <td>Ed Mazza</td>\n",
       "      <td>stephen colbert said former new york city mayo...</td>\n",
       "      <td>Today's \"Stormy Watch\" finds Hurricane Rudy \"m...</td>\n",
       "      <td>2018-05-04T02:14:53Z</td>\n",
       "      <td>{'id': 'the-huffington-post', 'name': 'The Huf...</td>\n",
       "      <td>the-huffington-post</td>\n",
       "      <td>The Huffington Post</td>\n",
       "      <td>Colbert Mocks Giuliani’s Bonkers Fox News Inte...</td>\n",
       "      <td>landfall</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/stephen-c...</td>\n",
       "      <td>https://img.huffingtonpost.com/asset/5aebbeac1...</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-05-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      author  \\\n",
       "date                                           \n",
       "2019-01-04  https://www.facebook.com/bbcnews   \n",
       "2018-10-11                     NEETI UPADHYE   \n",
       "2018-10-12                      Dell Cameron   \n",
       "2018-09-05                 Reuters Editorial   \n",
       "2018-05-04                          Ed Mazza   \n",
       "\n",
       "                                                      content  \\\n",
       "date                                                            \n",
       "2019-01-04  image copyrightepaimage caption  tens of thous...   \n",
       "2018-10-11            1 u s  paul manaforts trail of scandals   \n",
       "2018-10-12  the federal communications commission on frida...   \n",
       "2018-09-05   reuters  - tropical storm gordon was making l...   \n",
       "2018-05-04  stephen colbert said former new york city mayo...   \n",
       "\n",
       "                                                  description  \\\n",
       "date                                                            \n",
       "2019-01-04  Storm Pabuk has made landfall in southern Thai...   \n",
       "2018-10-11  Hurricane Michael made landfall in Florida at ...   \n",
       "2018-10-12  The Federal Communications Commission on Frida...   \n",
       "2018-09-05  Tropical storm Gordon was making landfall just...   \n",
       "2018-05-04  Today's \"Stormy Watch\" finds Hurricane Rudy \"m...   \n",
       "\n",
       "                     publishedAt  \\\n",
       "date                               \n",
       "2019-01-04  2019-01-04T07:28:56Z   \n",
       "2018-10-11  2018-10-11T16:18:46Z   \n",
       "2018-10-12  2018-10-12T22:25:00Z   \n",
       "2018-09-05  2018-09-05T03:12:45Z   \n",
       "2018-05-04  2018-05-04T02:14:53Z   \n",
       "\n",
       "                                                       source  \\\n",
       "date                                                            \n",
       "2019-01-04             {'id': 'bbc-news', 'name': 'BBC News'}   \n",
       "2018-10-11  {'id': 'the-new-york-times', 'name': 'The New ...   \n",
       "2018-10-12                {'id': None, 'name': 'Gizmodo.com'}   \n",
       "2018-09-05               {'id': 'reuters', 'name': 'Reuters'}   \n",
       "2018-05-04  {'id': 'the-huffington-post', 'name': 'The Huf...   \n",
       "\n",
       "                      source_id          source_name  \\\n",
       "date                                                   \n",
       "2019-01-04             bbc-news             BBC News   \n",
       "2018-10-11   the-new-york-times   The New York Times   \n",
       "2018-10-12                  NaN          Gizmodo.com   \n",
       "2018-09-05              reuters              Reuters   \n",
       "2018-05-04  the-huffington-post  The Huffington Post   \n",
       "\n",
       "                                                        title     types  \\\n",
       "date                                                                      \n",
       "2019-01-04  Thailand Pabuk: Tourist spots hit by worst sto...  landfall   \n",
       "2018-10-11  ‘Trees Flying By’: The Aftermath of Hurricane ...  landfall   \n",
       "2018-10-12  Widespread Cable, Internet, and Radio Outages ...  landfall   \n",
       "2018-09-05  Storm Gordon making landfall west of Alabama-M...  landfall   \n",
       "2018-05-04  Colbert Mocks Giuliani’s Bonkers Fox News Inte...  landfall   \n",
       "\n",
       "                                                          url  \\\n",
       "date                                                            \n",
       "2019-01-04     https://www.bbc.co.uk/news/world-asia-46756239   \n",
       "2018-10-11  https://www.nytimes.com/video/us/politics/1000...   \n",
       "2018-10-12  https://gizmodo.com/widespread-cable-internet-...   \n",
       "2018-09-05  https://www.reuters.com/article/us-storm-gordo...   \n",
       "2018-05-04  https://www.huffingtonpost.com/entry/stephen-c...   \n",
       "\n",
       "                                                   urlToImage  yes_disaster  \\\n",
       "date                                                                          \n",
       "2019-01-04  https://ichef.bbci.co.uk/news/1024/branded_new...             1   \n",
       "2018-10-11  https://static01.nyt.com/images/2018/10/12/us/...             1   \n",
       "2018-10-12  https://i.kinja-img.com/gawker-media/image/upl...             1   \n",
       "2018-09-05  https://s4.reutersmedia.net/resources_v2/image...             1   \n",
       "2018-05-04  https://img.huffingtonpost.com/asset/5aebbeac1...             1   \n",
       "\n",
       "                 date  \n",
       "date                   \n",
       "2019-01-04 2019-01-04  \n",
       "2018-10-11 2018-10-11  \n",
       "2018-10-12 2018-10-12  \n",
       "2018-09-05 2018-09-05  \n",
       "2018-05-04 2018-05-04  "
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[['content', 'yes_disaster']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>yes_disaster</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-04</th>\n",
       "      <td>image copyrightepaimage caption  tens of thous...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-11</th>\n",
       "      <td>1 u s  paul manaforts trail of scandals</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-12</th>\n",
       "      <td>the federal communications commission on frida...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-05</th>\n",
       "      <td>reuters  - tropical storm gordon was making l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-04</th>\n",
       "      <td>stephen colbert said former new york city mayo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      content  yes_disaster\n",
       "date                                                                       \n",
       "2019-01-04  image copyrightepaimage caption  tens of thous...             1\n",
       "2018-10-11            1 u s  paul manaforts trail of scandals             1\n",
       "2018-10-12  the federal communications commission on frida...             1\n",
       "2018-09-05   reuters  - tropical storm gordon was making l...             1\n",
       "2018-05-04  stephen colbert said former new york city mayo...             1"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "content         0\n",
       "yes_disaster    0\n",
       "date            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Examing Content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' reuters  - hurricane michael is strengthening and is expected to be a major hurricane when it makes landfall in northwestern florida on wednesday, the u s  national hurricane center  nhc  said in its latest advisory on the storm on tuesday  major hurricanes are those of category 3 and above on the on the five-step saffir-simpson scale  at 2 p m  et  1800 gmt , the center of michael was located about 310 miles  500 km  south-southwest of apalachicola, florida, the nhc said  it was carrying maximum sustained winds of 110 miles per hour  175 km per hour , the center said  the storm was moving north over the eastern gulf of mexico   life-threatening storm surge, hurricane force winds, and heavy rainfall expected along the northeastern gulf coast,  the miami-based forecaster said  reporting by karen rodrigues and k  sathya narayanan in bengaluru; editing by frances kerry'"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['content'][10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text): \n",
    "    '''\n",
    "    This clean_text function will focus on: \n",
    "    1. cleaning the content including removing prentecisis, \\r\\n, : and so on. \n",
    "    2. lower case all words.\n",
    "    3. remove stop words from articles. \n",
    "    '''\n",
    "    text = re.sub(r'\\r\\n', r' ', text)\n",
    "    text = re.sub(r'[\\\\\\.\\:\\*/]', r' ', text)\n",
    "    text = re.sub(r'[\\(\\)]', r' ', text)\n",
    "    text = re.sub(r'[\\\"\\“\\”\\—\\[\\]]', r' ', text)\n",
    "    text = re.sub(r\"'s\", r' ', text)\n",
    "    text = re.sub(r'[\\\\\"]', r' ', text)\n",
    "    text = text.lower()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' reuters  - hurricane michael is strengthening and is expected to be a major hurricane when it makes landfall in northwestern florida on wednesday, the u s  national hurricane center  nhc  said in its latest advisory on the storm on tuesday  major hurricanes are those of category 3 and above on the on the five-step saffir-simpson scale  at 2 p m  et  1800 gmt , the center of michael was located about 310 miles  500 km  south-southwest of apalachicola, florida, the nhc said  it was carrying maximum sustained winds of 110 miles per hour  175 km per hour , the center said  the storm was moving north over the eastern gulf of mexico   life-threatening storm surge, hurricane force winds, and heavy rainfall expected along the northeastern gulf coast,  the miami-based forecaster said  reporting by karen rodrigues and k  sathya narayanan in bengaluru; editing by frances kerry'"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(df_train['content'][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['content'] = df_train['content'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' reuters  - tropical storm gordon was making landfall just west of the alabama-mississippi border, the u s  national hurricane center  nhc  said in its latest advisory on tuesday  gordon was located about 35 miles  55 kilometers  south-southwest of mobile, alabama and was packing maximum sustained winds of 70 miles per hour  110 km h , the miami-based weather forecaster said   rapid weakening is forecast after gordon moves inland, and is forecast to become a tropical depression on wednesday,  the nhc added reporting by nallur sethuraman and vijaykumar vedala in bengaluru; editing by joseph radford'"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['content'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "custom_stop_words_final = pickle.load( open( \"save.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowercase(lst): \n",
    "    for i in range(len(lst)): \n",
    "        lst[i] = lst[i].lower()\n",
    "        \n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stop_words_final = lowercase(custom_stop_words_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1677"
      ]
     },
     "execution_count": 657,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(custom_stop_words_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        for word in nltk.word_tokenize(sent):\n",
    "            if word in custom_stop_words_final: \n",
    "                continue \n",
    "            if len(word) == 1: \n",
    "                continue \n",
    "            tokens.append(word.lower())\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular Train Test Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split the data and tag Documents \n",
    "train, test = train_test_split(df_train, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3722\n",
       "1    3721\n",
       "Name: yes_disaster, dtype: int64"
      ]
     },
     "execution_count": 686,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['yes_disaster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1616\n",
       "0    1575\n",
       "Name: yes_disaster, dtype: int64"
      ]
     },
     "execution_count": 687,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['yes_disaster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 50s, sys: 590 ms, total: 1min 50s\n",
      "Wall time: 1min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_tagged = train.apply(\n",
    "    lambda row: TaggedDocument(words=tokenize_text(row['content']), tags=[row.yes_disaster]), axis=1)\n",
    "\n",
    "test_tagged = test.apply(\n",
    "    lambda row: TaggedDocument(words=tokenize_text(row['content']), tags=[row.yes_disaster]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['genoa', 'italy', 'rescuers', 'searched', 'night', 'survivors', 'shattered', 'remains', 'motorway', 'bridge', 'genoa', 'investigators', 'determine', 'caused', 'catastrophic', 'collapse', '30', 'people', 'killed', 'tuesday', 'vast', 'span', 'morandi', 'bridge', 'collapsed', 'heavy', 'rainstorm', 'sending', 'vehicles', 'drivers', 'plunging', '100-meters', 'railway', 'tracks', 'rescuers', 'spent', 'wednesday', 'dawn', 'searching', 'tangled', 'remains', 'bridge', 'floodlights', 'fears', 'toll', 'rise', 'government', 'called', 'immense', 'tragedy', 'collapse', 'came', 'bridge', 'undergoing', 'maintenance', 'work', 'liguria', 'region', 'genoa', 'situated', 'experienced', 'torrential', 'rainfall', 'unfortunately', '30', 'dead', 'injured', 'condition', 'interior', 'minister', 'matteo', 'salvini', 'told', 'reporters', 'president', 'sergio', 'mattarella', 'said', 'catastrophe', 'hit', 'genoa', 'italy', 'attention', 'turned', 'caused', 'collapse', 'ultimately', 'responsible', 'italians', 'right', 'modern', 'efficient', 'infrastructure', 'accompanies', 'safely', 'everyday', 'lives', 'mattarella', 'said', 'statement', 'prime', 'minister', 'giuseppe', 'conte', 'said', 'infrastructure', 'country', 'needed', 'double-checked', 'allow', 'tragedy', 'like', 'happen', 'added'], tags=[1])"
      ]
     },
     "execution_count": 689,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tagged.values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['delays', 'caused', 'drawn-out', 'negotiations', 'nonprofit', 'providers', 'city', 'tries', 'reel', 'rates', 'long', 'inconsistent', 'mr', 'banks', 'said', 'city', 'contended', 'nuts', 'bolts', 'construction', 'pointing', 'unopened', 'landing', 'road', 'shelter', 'alarm', 'control', 'panel', 'wrong', 'place', 'inherent', 'challenges', 'developing', 'opening', 'buildings', 'new', 'city', 'said', 'obstacle', 'speaks', 'heart', 'plan', 'plea', 'empathy', 'steady', 'community', 'resistance', 'shelters', 'men', 'legal', 'challenge', 'mayor', 'plan', 'came', 'opposition', 'shelter', '104', 'elderly', 'men', 'crown', 'heights', 'city', 'prevailed', 'shelter', 'opening', 'delayed', 'months', 'shack', 'chief', 'executive', 'urban', 'pathways', 'shelter', 'provider', 'said', 'city', 'benefit', 'public', 'education', 'campaign', 'dispel', 'stereotypes', 'homeless', 'men', 'data', 'shows', 'homeless', 'people', 'street', 'likely', 'victims', 'crime', 'perpetrators', 'crime', 'mr', 'shack', 'said', 'risk', 'disabilities', 'need', 'support', 'crown', 'heights', 'men', 'shelter', 'entangled', 'legal', 'battle', 'summer', 'months', 'opened', 'floors', 'glistened', 'walls', 'free', 'scuffs', 'halls', 'teemed', 'security', 'staff', 'richard', 'heelan', 'victor', 'mcdade', 'staying', 'said', 'grateful', 'safe', 'clean', 'conditions', 'different', 'colors', 'different', 'languages', 'said', 'mr', 'heelan', '70-year-old', 'widower', 'old', 'farts', 'november', 'help', 'housing', 'specialists', 'shelter', 'mr', 'heelan', 'moved', 'apartment', 'brooklyn', 'mr', 'mcdade', 'lives', 'hall', 'continue', 'main', 'story'], tags=[0])"
      ]
     },
     "execution_count": 690,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tagged.values[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set-up Doc2Vec Training with Stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 692,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7443/7443 [00:00<00:00, 1157558.85it/s]\n"
     ]
    }
   ],
   "source": [
    "#building vocabulary model\n",
    "model_dbow = Doc2Vec(dm=0, \n",
    "                     vector_size= 100, \n",
    "                     window = 15, \n",
    "                     negative=10, \n",
    "                     hs=0, \n",
    "                     min_count=5, \n",
    "                     sample = 0, \n",
    "                     workers=cores)\n",
    "        \n",
    "model_dbow.build_vocab([x for x in tqdm(train_tagged.values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7443/7443 [00:00<00:00, 1794355.94it/s]\n",
      "100%|██████████| 7443/7443 [00:00<00:00, 3017126.19it/s]\n",
      "100%|██████████| 7443/7443 [00:00<00:00, 1925385.76it/s]\n",
      "100%|██████████| 7443/7443 [00:00<00:00, 2302227.48it/s]\n",
      "100%|██████████| 7443/7443 [00:00<00:00, 2921138.27it/s]\n",
      "100%|██████████| 7443/7443 [00:00<00:00, 2034156.82it/s]\n",
      "100%|██████████| 7443/7443 [00:00<00:00, 2750744.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51 s, sys: 488 ms, total: 51.5 s\n",
      "Wall time: 16.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(7):\n",
    "    model_dbow.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), \n",
    "                     total_examples=len(train_tagged.values), epochs=1)\n",
    "    model_dbow.alpha -= 0.001\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_for_learning(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
    "    return targets, regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 21s, sys: 569 ms, total: 2min 22s\n",
      "Wall time: 2min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_train, X_train = vec_for_learning(model_dbow, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow, test_tagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Evaluation Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate all of the models, and create lists of models and modelnames (strings)\n",
    "\n",
    "lr  = LogisticRegression(solver='liblinear', multi_class='auto')\n",
    "\n",
    "dt  = DecisionTreeClassifier(max_depth    = None,\n",
    "                             min_samples_split = 2,\n",
    "                             max_features = None,\n",
    "                             random_state = 42)\n",
    "\n",
    "bag = BaggingClassifier(n_estimators= 100)\n",
    "\n",
    "rf  = RandomForestClassifier(n_estimators= 100, max_features=100, random_state = 42)\n",
    "\n",
    "et  = ExtraTreesClassifier(n_estimators= 100, random_state = 42)\n",
    "\n",
    "ab  = AdaBoostClassifier(n_estimators= 1000)\n",
    "\n",
    "gb  = GradientBoostingClassifier(n_estimators=1000)\n",
    "\n",
    "svc = svm.SVC()\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors= 100)\n",
    "\n",
    "\n",
    "models_set1     = [ lr,   dt,   bag,   rf,   et]\n",
    "modelnames_set1 = ['lr', 'dt', 'bag', 'rf', 'et']\n",
    "\n",
    "models_set2     = [ ab,   gb,   svc ,  knn ]\n",
    "modelnames_set2 = ['ab', 'gb', 'svc', 'knn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Define a function to fit and score any instantiated model\n",
    "#  Parameters: instantiated model, modelname(string), X_train, X_test, y_train, y_test\n",
    "#  Returns:    train score, test score, overfit amt, fit time\n",
    "\n",
    "def fit_score(model, modelname, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    time_start = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    time_end   = time.time()\n",
    "    fit_time   = time_end - time_start\n",
    "    \n",
    "    model_train_score = model.score(X_train, y_train)\n",
    "    model_test_score  = model.score(X_test, y_test)\n",
    "    overfit_amt       = model_train_score - model_test_score\n",
    "    \n",
    "    print(f'\\n{modelname.upper()} fit time: {fit_time:.2f} sec')\n",
    "    print(f'Train score: {model_train_score:.6f}  \\\n",
    "    Test score: {model_test_score:.6f}  \\\n",
    "    Overfit: {overfit_amt:.4f}')\n",
    "    \n",
    "    return model_train_score, model_test_score, overfit_amt, fit_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LR fit time: 0.23 sec\n",
      "Train score: 0.839446      Test score: 0.788154      Overfit: 0.0513\n",
      "\n",
      "DT fit time: 0.88 sec\n",
      "Train score: 1.000000      Test score: 0.667502      Overfit: 0.3325\n",
      "\n",
      "BAG fit time: 54.05 sec\n",
      "Train score: 1.000000      Test score: 0.781573      Overfit: 0.2184\n",
      "\n",
      "RF fit time: 56.01 sec\n",
      "Train score: 1.000000      Test score: 0.776872      Overfit: 0.2231\n",
      "\n",
      "ET fit time: 1.23 sec\n",
      "Train score: 1.000000      Test score: 0.783453      Overfit: 0.2165\n"
     ]
    }
   ],
   "source": [
    "# Round 1\n",
    "# code from Manu\n",
    "# use a for loop to call fit_score function on all nine models\n",
    "# dictionary technique adapted from StackOverflow\n",
    "\n",
    "results_dict = {}\n",
    "for model, modelname in zip(models_set1, modelnames_set1):\n",
    "    temp1, temp2, temp3, temp4 = fit_score(\n",
    "                                            model, modelname,\n",
    "                                            X_train, X_test,\n",
    "                                            y_train, y_test)\n",
    "    results_dict[modelname] = {}\n",
    "    results_dict[modelname]['train_score'] = temp1\n",
    "    results_dict[modelname]['test_score']  = temp2\n",
    "    results_dict[modelname]['overfit_amt'] = temp3\n",
    "    results_dict[modelname]['fit_time']    = temp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>overfit_amt</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>0.226733</td>\n",
       "      <td>0.051292</td>\n",
       "      <td>0.788154</td>\n",
       "      <td>0.839446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>0.884789</td>\n",
       "      <td>0.332498</td>\n",
       "      <td>0.667502</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bag</th>\n",
       "      <td>54.047184</td>\n",
       "      <td>0.218427</td>\n",
       "      <td>0.781573</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>56.007343</td>\n",
       "      <td>0.223128</td>\n",
       "      <td>0.776872</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>et</th>\n",
       "      <td>1.234127</td>\n",
       "      <td>0.216547</td>\n",
       "      <td>0.783453</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fit_time  overfit_amt  test_score  train_score\n",
       "lr    0.226733     0.051292    0.788154     0.839446\n",
       "dt    0.884789     0.332498    0.667502     1.000000\n",
       "bag  54.047184     0.218427    0.781573     1.000000\n",
       "rf   56.007343     0.223128    0.776872     1.000000\n",
       "et    1.234127     0.216547    0.783453     1.000000"
      ]
     },
     "execution_count": 709,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df1 = pd.DataFrame(results_dict)\n",
    "results_table1 = results_df1.T\n",
    "results_table1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AB fit time: 82.29 sec\n",
      "Train score: 0.921000      Test score: 0.756816      Overfit: 0.1642\n",
      "\n",
      "GB fit time: 61.36 sec\n",
      "Train score: 0.993685      Test score: 0.782200      Overfit: 0.2115\n",
      "\n",
      "SVC fit time: 6.81 sec\n",
      "Train score: 0.865243      Test score: 0.795362      Overfit: 0.0699\n",
      "\n",
      "KNN fit time: 0.03 sec\n",
      "Train score: 0.790676      Test score: 0.754936      Overfit: 0.0357\n"
     ]
    }
   ],
   "source": [
    "# Round 2\n",
    "# code from Manu\n",
    "# use a for loop to call fit_score function on all nine models\n",
    "# dictionary technique adapted from StackOverflow\n",
    "\n",
    "results_dict = {}\n",
    "for model, modelname in zip(models_set2, modelnames_set2):\n",
    "    temp1, temp2, temp3, temp4 = fit_score(\n",
    "                                            model, modelname,\n",
    "                                            X_train, X_test,\n",
    "                                            y_train, y_test)\n",
    "    results_dict[modelname] = {}\n",
    "    results_dict[modelname]['train_score'] = temp1\n",
    "    results_dict[modelname]['test_score']  = temp2\n",
    "    results_dict[modelname]['overfit_amt'] = temp3\n",
    "    results_dict[modelname]['fit_time']    = temp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>overfit_amt</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ab</th>\n",
       "      <td>82.288448</td>\n",
       "      <td>0.164184</td>\n",
       "      <td>0.756816</td>\n",
       "      <td>0.921000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>61.360885</td>\n",
       "      <td>0.211485</td>\n",
       "      <td>0.782200</td>\n",
       "      <td>0.993685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svc</th>\n",
       "      <td>6.808115</td>\n",
       "      <td>0.069881</td>\n",
       "      <td>0.795362</td>\n",
       "      <td>0.865243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>0.028084</td>\n",
       "      <td>0.035740</td>\n",
       "      <td>0.754936</td>\n",
       "      <td>0.790676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fit_time  overfit_amt  test_score  train_score\n",
       "ab   82.288448     0.164184    0.756816     0.921000\n",
       "gb   61.360885     0.211485    0.782200     0.993685\n",
       "svc   6.808115     0.069881    0.795362     0.865243\n",
       "knn   0.028084     0.035740    0.754936     0.790676"
      ]
     },
     "execution_count": 711,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df2 = pd.DataFrame(results_dict)\n",
    "results_table2 = results_df2.T\n",
    "results_table2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.05398109e+00, -4.19707072e-01, -1.55357708e-01,\n",
       "         1.86733531e-01, -3.78406686e-01, -2.12960114e-03,\n",
       "        -3.70778395e-01,  1.78435492e-01,  3.85730247e-01,\n",
       "         2.69375798e-01,  3.56583024e-01,  3.62967668e-01,\n",
       "        -2.82888650e-01, -2.47805072e-02, -1.59810551e-01,\n",
       "         4.09249568e-01,  2.51200497e-01, -2.81464073e-01,\n",
       "        -6.90969018e-02,  1.75199775e-01, -3.44157278e-03,\n",
       "        -1.01338714e-01, -2.45023596e-01, -3.98546962e-01,\n",
       "         6.33128904e-01, -3.82032631e-01, -4.16819017e-01,\n",
       "        -1.22501754e-01, -7.03152288e-02, -6.91133873e-02,\n",
       "         1.87552217e-01,  9.63241756e-03,  1.26774454e-01,\n",
       "         2.54359997e-01,  8.80700946e-02,  6.01290879e-01,\n",
       "        -4.41115998e-01, -4.68605717e-01,  5.40738027e-01,\n",
       "        -4.64032028e-02, -1.48123523e-01, -2.95351227e-01,\n",
       "         2.92114043e-01, -3.05020018e-01, -3.56972348e-01,\n",
       "         2.93084029e-01,  1.04505475e-01, -2.64743274e-01,\n",
       "        -3.83546849e-01, -3.01806359e-02, -4.02014680e-02,\n",
       "        -1.90836492e-01,  2.03292850e-02,  3.83481954e-02,\n",
       "        -4.13742750e-01, -5.20209033e-01,  2.26482830e-03,\n",
       "        -3.64223053e-01, -4.56961463e-01,  1.86861861e-01,\n",
       "         2.66135571e-01,  7.66281149e-02, -3.85291548e-01,\n",
       "         6.66934231e-02,  1.63380462e-01, -1.76162024e-01,\n",
       "         2.26861715e-01, -3.01720995e-01,  3.66641175e-02,\n",
       "         1.30453629e-01,  1.67041500e-03, -2.67883566e-01,\n",
       "        -8.74845181e-02, -2.44767880e-01,  3.19044850e-01,\n",
       "         3.43579407e-02,  4.33279823e-01, -1.32949475e-01,\n",
       "         2.10276434e-02, -8.92513789e-05,  1.58372169e-02,\n",
       "        -2.86137597e-01, -2.64421585e-01,  7.22558609e-04,\n",
       "         7.57768636e-01,  6.31676796e-01,  1.23707128e-01,\n",
       "        -3.25545723e-02,  5.22593381e-01, -5.06589629e-01,\n",
       "        -2.33520957e-01, -3.72561340e-02,  1.39212179e-01,\n",
       "        -4.59318899e-01,  5.64874609e-01, -4.07397921e-01,\n",
       "         3.20551452e-02, -1.42189724e-01, -2.93186202e-01,\n",
       "         8.68226826e-01]])"
      ]
     },
     "execution_count": 712,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up Doc2Vec Training with Stopwords and Time-series Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017 data shape (1013, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    512\n",
       "0    501\n",
       "Name: yes_disaster, dtype: int64"
      ]
     },
     "execution_count": 713,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('2017 data shape', df_train['2017'].shape)\n",
    "\n",
    "df_train['2017']['yes_disaster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018 data shape (7758, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    4006\n",
       "0    3752\n",
       "Name: yes_disaster, dtype: int64"
      ]
     },
     "execution_count": 715,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('2018 data shape', df_train['2018'].shape)\n",
    "\n",
    "df_train['2018']['yes_disaster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_2018 = shuffle(df_train['2018'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019 data shape (1863, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    1044\n",
       "1     819\n",
       "Name: yes_disaster, dtype: int64"
      ]
     },
     "execution_count": 717,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('2019 data shape', df_train['2019'].shape)\n",
    "\n",
    "df_train['2019']['yes_disaster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3118\n",
       "0    2895\n",
       "Name: yes_disaster, dtype: int64"
      ]
     },
     "execution_count": 718,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train data includes: 2017, and 6000 rows from 2018 \n",
    "train_df = pd.concat([df_train['2017'], df_train_2018[:5000]])\n",
    "train_df['yes_disaster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>yes_disaster</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-12-21</th>\n",
       "      <td>five days after hurricane harvey slammed into ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-13</th>\n",
       "      <td>federal reserve officials followed through on ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-13</th>\n",
       "      <td>for developing communities in many parts of th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-27</th>\n",
       "      <td>drivers are poised to pay the highest year-end...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-04</th>\n",
       "      <td>bob bentz had just installed underground utili...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      content  yes_disaster\n",
       "date                                                                       \n",
       "2017-12-21  five days after hurricane harvey slammed into ...             1\n",
       "2017-12-13  federal reserve officials followed through on ...             1\n",
       "2017-11-13  for developing communities in many parts of th...             1\n",
       "2017-11-27  drivers are poised to pay the highest year-end...             1\n",
       "2017-12-04  bob bentz had just installed underground utili...             1"
      ]
     },
     "execution_count": 719,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('../data/train_csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2402\n",
       "1    2219\n",
       "Name: yes_disaster, dtype: int64"
      ]
     },
     "execution_count": 721,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test data includes: 2018, and 2019\n",
    "test_df = pd.concat([df_train_2018[5000:], df_train['2019']])\n",
    "test_df['yes_disaster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>yes_disaster</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-23</th>\n",
       "      <td>now playing  unruly passenger removed from ame...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-16</th>\n",
       "      <td>the dinner bell is ringing for the trade bar ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-05</th>\n",
       "      <td>day-and-date announce and release is a new wri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-14</th>\n",
       "      <td>cambridge, vt     an avalanche has hit vermon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-17</th>\n",
       "      <td>the scientists examined precipitation trends a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      content  yes_disaster\n",
       "date                                                                       \n",
       "2018-04-23  now playing  unruly passenger removed from ame...             1\n",
       "2018-03-16   the dinner bell is ringing for the trade bar ...             0\n",
       "2018-02-05  day-and-date announce and release is a new wri...             0\n",
       "2018-03-14   cambridge, vt     an avalanche has hit vermon...             1\n",
       "2018-05-17  the scientists examined precipitation trends a...             1"
      ]
     },
     "execution_count": 722,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('../data/test_csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 49s, sys: 565 ms, total: 1min 50s\n",
      "Wall time: 1min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_tagged2 = train_df.apply(\n",
    "    lambda row: TaggedDocument(words=tokenize_text(row['content']), tags=[row.yes_disaster]), axis=1)\n",
    "\n",
    "test_tagged2 = test_df.apply(\n",
    "    lambda row: TaggedDocument(words=tokenize_text(row['content']), tags=[row.yes_disaster]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['students', 'participate', 'training', 'program', 'shelter', 'earthquake', 'school', 'seoul', 'south', 'korea', 'nov', '16', '2017', 'photo', 'yonhap', 'epa-efe', 'seoul', 'south', 'korea', 'magnitude', 'earthquake', 'south', 'korea', 'second-strongest', 'decades', 'damaged', 'infrastructure', 'injured', 'dozens', 'people', 'left', '1,500', 'homeless', 'officials', 'said', 'thursday', 'deaths', 'reported', 'quake', 'rattled', 'southeastern', 'coastal', 'region', 'port', 'city', 'pohang', 'wednesday', 'afternoon', 'thursday', 'morning', '1,536', 'people', 'forced', 'evacuate', 'homes', '57', 'people', 'injured', 'ministry', 'interior', 'safety', 'said', 'statement', '1,000', 'houses', 'dozens', 'buildings', 'cars', 'damaged', 'destroyed', 'cracks', 'damage', 'military', 'facilities', 'bridges', 'port', 'facilities', 'water', 'supply', 'facilities', 'media', 'images', 'showed', 'crumbled', 'walls', 'piled', 'damaged', 'cars', 'broken', 'windows', 'cracks', 'buildings', 'quake', 'forced', 'education', 'ministry', 'university', 'entrance', 'exam', 'week', 'buildings', 'chosen', 'test', 'venues', 'cracks', 'students', 'southeastern', 'region', 'displaced', 'homes', 'complained', 'anxieties', 'annual', 'test', 'administered', 'government', 'huge', 'national', 'event', 'south', 'korea', 'diplomas', 'colleges', 'guarantee', 'better', 'jobs', 'spouses', 'second-strongest', 'quake', 'south', 'korea', 'country', 'officially', 'began', 'monitoring', '1978', 'biggest', 'quake', 'occurred', 'september', '2016', 'magnitude', 'occurred', 'near', 'ancient', 'city', 'gyeongju', 'close', 'pohang', 'quake', 'caused', 'injuries', 'deaths', 'south', 'korea', 'state-run', 'korea', 'meteorological', 'administration', 'said', 'epicenter', 'wednesday', 'quake', 'inside', 'pohang', 'geological', 'survey', 'said', 'centered', 'kilometers', 'miles', 'northwest', 'port', 'city', 'shaking', 'felt', 'seoul', '300', 'kilometers', '186', 'miles', 'away', 'south', 'korea', 'relatively', 'little', 'seismic', 'activity', 'unlike', 'neighboring', 'read', 'share', 'story', 'https', 'usat', 'ly', '2imlfcp'], tags=[1])"
      ]
     },
     "execution_count": 652,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tagged2[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7013/7013 [00:00<00:00, 1425681.17it/s]\n"
     ]
    }
   ],
   "source": [
    "#building vocabulary model\n",
    "model_dbow2 = Doc2Vec(dm=0, \n",
    "                     vector_size= 100, \n",
    "                     window = 15, \n",
    "                     negative=10, \n",
    "                     hs=0, \n",
    "                     min_count=5, \n",
    "                     sample = 0, \n",
    "                     workers=cores)\n",
    "        \n",
    "model_dbow2.build_vocab([x for x in tqdm(train_tagged.values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6013/6013 [00:00<00:00, 1707654.54it/s]\n",
      "100%|██████████| 6013/6013 [00:00<00:00, 2587233.27it/s]\n",
      "100%|██████████| 6013/6013 [00:00<00:00, 2425733.38it/s]\n",
      "100%|██████████| 6013/6013 [00:00<00:00, 2559921.84it/s]\n",
      "100%|██████████| 6013/6013 [00:00<00:00, 2560701.59it/s]\n",
      "100%|██████████| 6013/6013 [00:00<00:00, 2203420.40it/s]\n",
      "100%|██████████| 6013/6013 [00:00<00:00, 2722110.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.2 s, sys: 368 ms, total: 41.6 s\n",
      "Wall time: 12.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(7):\n",
    "    model_dbow2.train(utils.shuffle([x for x in tqdm(train_tagged2.values)]), \n",
    "                     total_examples=len(train_tagged2.values), epochs=1)\n",
    "    model_dbow2.alpha -= 0.002\n",
    "    model_dbow2.min_alpha = model_dbow2.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_for_learning(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
    "    return targets, regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 17s, sys: 543 ms, total: 2min 18s\n",
      "Wall time: 2min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_train, X_train = vec_for_learning(model_dbow2, train_tagged2)\n",
    "y_test, X_test = vec_for_learning(model_dbow2, test_tagged2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Evaluation Models with Time-series train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate all of the models, and create lists of models and modelnames (strings)\n",
    "\n",
    "lr  = LogisticRegression(solver='liblinear', multi_class='auto')\n",
    "\n",
    "dt  = DecisionTreeClassifier(max_depth    = None,\n",
    "                             min_samples_split = 2,\n",
    "                             max_features = None,\n",
    "                             random_state = 42)\n",
    "\n",
    "bag = BaggingClassifier(n_estimators= 100)\n",
    "\n",
    "rf  = RandomForestClassifier(n_estimators= 100, max_features=100, random_state = 42)\n",
    "\n",
    "et  = ExtraTreesClassifier(n_estimators= 100, random_state = 42)\n",
    "\n",
    "ab  = AdaBoostClassifier(n_estimators= 1000)\n",
    "\n",
    "gb  = GradientBoostingClassifier(n_estimators=1000)\n",
    "\n",
    "svc = svm.SVC()\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors= 100)\n",
    "\n",
    "\n",
    "models_set1     = [ lr,   dt,   bag,   rf,   et]\n",
    "modelnames_set1 = ['lr', 'dt', 'bag', 'rf', 'et']\n",
    "\n",
    "models_set2     = [ ab,   gb,   svc ,  knn ]\n",
    "modelnames_set2 = ['ab', 'gb', 'svc', 'knn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Define a function to fit and score any instantiated model\n",
    "#  Parameters: instantiated model, modelname(string), X_train, X_test, y_train, y_test\n",
    "#  Returns:    train score, test score, overfit amt, fit time\n",
    "\n",
    "def fit_score(model, modelname, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    time_start = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    time_end   = time.time()\n",
    "    fit_time   = time_end - time_start\n",
    "    \n",
    "    model_train_score = model.score(X_train, y_train)\n",
    "    model_test_score  = model.score(X_test, y_test)\n",
    "    overfit_amt       = model_train_score - model_test_score\n",
    "    \n",
    "    print(f'\\n{modelname.upper()} fit time: {fit_time:.2f} sec')\n",
    "    print(f'Train score: {model_train_score:.6f}  \\\n",
    "    Test score: {model_test_score:.6f}  \\\n",
    "    Overfit: {overfit_amt:.4f}')\n",
    "    \n",
    "    return model_train_score, model_test_score, overfit_amt, fit_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LR fit time: 0.22 sec\n",
      "Train score: 0.839446      Test score: 0.788154      Overfit: 0.0513\n",
      "\n",
      "DT fit time: 0.89 sec\n",
      "Train score: 1.000000      Test score: 0.667502      Overfit: 0.3325\n",
      "\n",
      "BAG fit time: 58.04 sec\n",
      "Train score: 1.000000      Test score: 0.780946      Overfit: 0.2191\n",
      "\n",
      "RF fit time: 57.34 sec\n",
      "Train score: 1.000000      Test score: 0.776872      Overfit: 0.2231\n",
      "\n",
      "ET fit time: 1.20 sec\n",
      "Train score: 1.000000      Test score: 0.783453      Overfit: 0.2165\n"
     ]
    }
   ],
   "source": [
    "# Round 1\n",
    "# code from Manu\n",
    "# use a for loop to call fit_score function on all nine models\n",
    "# dictionary technique adapted from StackOverflow\n",
    "\n",
    "results_dict = {}\n",
    "for model, modelname in zip(models_set1, modelnames_set1):\n",
    "    temp1, temp2, temp3, temp4 = fit_score(\n",
    "                                            model, modelname,\n",
    "                                            X_train, X_test,\n",
    "                                            y_train, y_test)\n",
    "    results_dict[modelname] = {}\n",
    "    results_dict[modelname]['train_score'] = temp1\n",
    "    results_dict[modelname]['test_score']  = temp2\n",
    "    results_dict[modelname]['overfit_amt'] = temp3\n",
    "    results_dict[modelname]['fit_time']    = temp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>overfit_amt</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>0.218981</td>\n",
       "      <td>0.051292</td>\n",
       "      <td>0.788154</td>\n",
       "      <td>0.839446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>0.892328</td>\n",
       "      <td>0.332498</td>\n",
       "      <td>0.667502</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bag</th>\n",
       "      <td>58.040239</td>\n",
       "      <td>0.219054</td>\n",
       "      <td>0.780946</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>57.343921</td>\n",
       "      <td>0.223128</td>\n",
       "      <td>0.776872</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>et</th>\n",
       "      <td>1.200405</td>\n",
       "      <td>0.216547</td>\n",
       "      <td>0.783453</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fit_time  overfit_amt  test_score  train_score\n",
       "lr    0.218981     0.051292    0.788154     0.839446\n",
       "dt    0.892328     0.332498    0.667502     1.000000\n",
       "bag  58.040239     0.219054    0.780946     1.000000\n",
       "rf   57.343921     0.223128    0.776872     1.000000\n",
       "et    1.200405     0.216547    0.783453     1.000000"
      ]
     },
     "execution_count": 728,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df1 = pd.DataFrame(results_dict)\n",
    "results_table1 = results_df1.T\n",
    "results_table1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AB fit time: 79.99 sec\n",
      "Train score: 0.921000      Test score: 0.756816      Overfit: 0.1642\n",
      "\n",
      "GB fit time: 61.00 sec\n",
      "Train score: 0.993685      Test score: 0.782200      Overfit: 0.2115\n",
      "\n",
      "SVC fit time: 5.17 sec\n",
      "Train score: 0.865243      Test score: 0.795362      Overfit: 0.0699\n",
      "\n",
      "KNN fit time: 0.02 sec\n",
      "Train score: 0.790676      Test score: 0.754936      Overfit: 0.0357\n"
     ]
    }
   ],
   "source": [
    "# Round 2\n",
    "# code from Manu\n",
    "# use a for loop to call fit_score function on all nine models\n",
    "# dictionary technique adapted from StackOverflow\n",
    "\n",
    "results_dict = {}\n",
    "for model, modelname in zip(models_set2, modelnames_set2):\n",
    "    temp1, temp2, temp3, temp4 = fit_score(\n",
    "                                            model, modelname,\n",
    "                                            X_train, X_test,\n",
    "                                            y_train, y_test)\n",
    "    results_dict[modelname] = {}\n",
    "    results_dict[modelname]['train_score'] = temp1\n",
    "    results_dict[modelname]['test_score']  = temp2\n",
    "    results_dict[modelname]['overfit_amt'] = temp3\n",
    "    results_dict[modelname]['fit_time']    = temp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>overfit_amt</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ab</th>\n",
       "      <td>79.992350</td>\n",
       "      <td>0.164184</td>\n",
       "      <td>0.756816</td>\n",
       "      <td>0.921000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>61.001763</td>\n",
       "      <td>0.211485</td>\n",
       "      <td>0.782200</td>\n",
       "      <td>0.993685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svc</th>\n",
       "      <td>5.169062</td>\n",
       "      <td>0.069881</td>\n",
       "      <td>0.795362</td>\n",
       "      <td>0.865243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>0.021383</td>\n",
       "      <td>0.035740</td>\n",
       "      <td>0.754936</td>\n",
       "      <td>0.790676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fit_time  overfit_amt  test_score  train_score\n",
       "ab   79.992350     0.164184    0.756816     0.921000\n",
       "gb   61.001763     0.211485    0.782200     0.993685\n",
       "svc   5.169062     0.069881    0.795362     0.865243\n",
       "knn   0.021383     0.035740    0.754936     0.790676"
      ]
     },
     "execution_count": 731,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df2 = pd.DataFrame(results_dict)\n",
    "results_table2 = results_df2.T\n",
    "results_table2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch for the hyperparameter for KNN and Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logreg__C': 1, 'logreg__solver': 'liblinear'}"
      ]
     },
     "execution_count": 732,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loggit_pipe = Pipeline([\n",
    "    ('logreg', LogisticRegression())\n",
    "])\n",
    "\n",
    "#parameters for grid search \n",
    "params = {\n",
    "    'logreg__C': [0.001,0.01,0.1,1,10,100,1000],\n",
    "    'logreg__solver' : ['liblinear', 'sag']    \n",
    "}\n",
    "\n",
    "#gridsearch \n",
    "gs = GridSearchCV(loggit_pipe, param_grid = params , cv = 5)\n",
    "gs.fit(X_train, y_train)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 0.8394464597608491\n",
      "test score 0.7881541836414917\n"
     ]
    }
   ],
   "source": [
    "print('train score', gs.score(X_train, y_train))\n",
    "print('test score', gs.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 1s, sys: 2.9 s, total: 7min 4s\n",
      "Wall time: 7min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#KNN \n",
    "knn_pipe = Pipeline([\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "#parameters for grid search \n",
    "params = {\n",
    "    'knn__n_neighbors': [50,100,150, 200, 250],\n",
    "    'knn__weights' : ['uniform', 'distance']    \n",
    "}\n",
    "\n",
    "#gridsearch \n",
    "gs_knn = GridSearchCV(knn_pipe, param_grid = params , cv = 5)\n",
    "gs_knn.fit(X_train, y_train)\n",
    "gs_knn.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'knn__n_neighbors': 150, 'knn__weights': 'uniform'}"
      ]
     },
     "execution_count": 735,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_knn.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 0.791347574902593\n",
      "test score 0.7649639611407082\n"
     ]
    }
   ],
   "source": [
    "print('train score', gs_knn.score(X_train, y_train))\n",
    "print('test score', gs_knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch to find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7724/7724 [00:00<00:00, 1207619.34it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2172678.16it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1495973.59it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2728151.92it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2941687.47it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2717852.69it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1692446.14it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2718080.72it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2888703.00it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2424547.53it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2681854.64it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2662459.25it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2435117.57it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2959423.05it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2625987.20it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2724710.18it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 3054285.29it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2281947.18it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1858041.07it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2504584.78it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1555967.73it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2913381.66it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2846069.06it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2316042.61it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 3044526.28it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2913643.68it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1727184.74it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2648961.90it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2438233.17it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1241019.12it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 3026607.26it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2319690.97it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 3222600.63it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2365075.49it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2939018.79it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2910502.57it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2808565.59it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2593611.73it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2418935.57it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1933791.21it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2550929.46it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 3042239.09it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2856357.26it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2921526.21it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2627904.29it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2993882.64it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2543918.66it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2579979.62it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2765412.21it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 3099579.42it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2730221.14it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2632602.32it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 3100766.09it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2768247.81it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2741078.27it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2970821.10it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2462137.41it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2343518.81it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 3110590.89it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2470021.66it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2949454.12it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2758348.58it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2734830.67it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2813932.43it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2208220.58it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2991394.65it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2951603.87it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2999981.86it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2762582.42it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 3082180.96it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2777503.78it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2870021.62it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2682742.97it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 3026607.26it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2779410.10it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2755767.62it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 3039670.12it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2733215.57it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2545917.81it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2586571.19it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 3004154.68it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2945967.45it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2493212.57it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2665306.80it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2659617.77it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2966197.04it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2940352.52it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 3178650.32it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 3044526.28it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2384046.22it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2348615.64it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 3018429.53it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2865198.91it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2888445.44it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2357846.00it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2042931.27it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2870275.90it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2943558.43it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2461389.16it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2487660.61it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2948112.12it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2821775.46it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 3015058.55it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2978742.56it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2828180.19it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1760217.55it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2862920.12it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2518995.73it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2533375.36it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 3146237.17it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 3151440.09it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 3044526.28it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2788500.96it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2613699.40it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 3011415.14it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2970548.70it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 3099579.42it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 3013656.19it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2679858.06it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 3004433.28it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2501490.55it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 3024064.60it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 3086879.86it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 3191488.93it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 3082180.96it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2797651.48it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2970548.70it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2796444.03it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2637961.41it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2640541.54it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2454303.34it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2634314.86it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2545717.75it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 3052846.22it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2581624.36it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2815155.03it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2854343.97it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2421285.81it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2390555.20it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 3053997.37it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2604035.37it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2951603.87it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 270846.85it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2795478.82it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2034719.51it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1995368.57it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1983639.73it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1735698.05it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2041129.29it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1606187.61it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1785833.42it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1697945.71it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2501876.91it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 3191803.36it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2797651.48it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 3100766.09it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 3015339.17it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2844819.47it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 3024064.60it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2813932.43it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2777027.61it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2692329.77it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2657000.25it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2779410.10it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2407610.29it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2895415.51it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2707178.42it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2761875.88it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 3125897.73it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2276495.26it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2850325.89it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2998593.49it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2489954.97it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2958342.08it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2841824.92it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2485370.47it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1946572.38it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1683125.73it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1630930.53it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1965825.49it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1777699.96it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1735419.12it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1972528.26it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2342163.40it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2493980.30it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2080318.76it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1944586.08it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1947508.51it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1992668.48it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1989120.41it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1745611.51it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1965467.70it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1950439.74it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1635293.73it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2782513.45it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2874860.60it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1993158.86it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1947040.33it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1758975.14it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1816880.94it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1967974.98it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1885288.88it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1985098.29it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1738492.30it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1920493.46it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1921404.67it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1715750.67it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1831983.95it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1902895.98it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1687157.80it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2503036.71it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2157054.67it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2082056.82it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1807151.45it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1756400.33it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2006615.30it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2243390.63it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2120764.87it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1929989.52it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1854849.66it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1824247.09it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1871133.42it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1685051.71it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1115707.69it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1692004.18it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1961540.57it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2264877.24it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1696434.21it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1567713.72it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1657888.75it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1673647.99it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1751367.94it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1822605.01it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1861671.31it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1593233.21it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1911428.64it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2441908.80it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1591198.63it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1781414.50it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1675465.66it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1447190.39it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1578868.57it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1561969.24it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1167662.79it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1519906.36it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1491016.39it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1396173.25it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1529810.84it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1583421.51it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1593233.21it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1519264.87it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1538967.46it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2257302.40it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2111641.51it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1696878.49it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1484797.84it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1552835.36it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1452706.34it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2574648.66it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2397277.20it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1952085.09it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1734211.45it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1694659.42it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1569916.85it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1449910.67it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1353193.44it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1476339.96it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1637856.63it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2588637.96it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1903790.57it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1517841.27it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1687245.67it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1679548.14it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1671920.53it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1578330.12it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1240021.59it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1450494.92it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1306270.07it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1841669.27it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2290659.98it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1994263.10it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1085283.71it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1932407.04it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1755353.49it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1488208.19it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1766263.44it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7724/7724 [00:00<00:00, 1584970.85it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1530461.27it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1507809.93it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1420850.14it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1318175.70it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1143066.97it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 971680.64it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 938548.12it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2576491.50it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2309932.56it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1772447.98it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1125436.12it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1012716.60it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1421161.79it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2790422.40it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2450404.97it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1965467.70it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1701334.11it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1662824.21it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1519336.12it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1573729.92it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1539918.44it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1467246.56it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2767538.36it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2239513.62it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2006863.91it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1816167.96it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1672006.82it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1780631.20it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1657803.91it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1633809.27it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1436474.26it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1430385.63it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1514506.29it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2322351.55it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2300745.98it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1874706.56it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1819942.93it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1803328.92it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1761365.96it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1818308.59it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1841669.27it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1633068.06it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1627898.30it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1686104.10it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1660267.72it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1531546.55it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1471244.51it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1461817.71it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1342594.45it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2507104.48it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2255102.61it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1638519.33it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1503890.27it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1343373.86it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1263969.57it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1960472.26it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 816143.19it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1337936.90it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1266390.59it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1170531.64it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1140250.74it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1261066.72it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1140692.37it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1366838.41it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2660709.93it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2213803.75it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1704646.36it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1592528.34it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1636119.59it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1705094.95it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1651044.95it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1541457.11it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1603167.27it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1544175.60it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1290760.75it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2401720.22it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2119654.81it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1686806.42it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1437621.66it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1435964.90it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1460960.73it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1272908.89it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 889557.76it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 740837.05it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1289271.10it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 929927.21it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 936811.18it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1181028.91it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1048576.00it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 943660.37it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1112833.34it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2574648.66it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2210782.32it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1671489.22it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1534666.23it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1574112.24it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1631916.39it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2341317.06it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2589258.64it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1659332.31it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1603167.27it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1572813.09it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1560990.85it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1550086.32it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1202152.37it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1413904.95it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2150468.24it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2199226.40it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1679112.89it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1572431.40it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1538675.09it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1451599.79it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1491634.24it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1409475.92it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1269516.99it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1237038.61it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1154883.93it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2298786.92it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1513940.10it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1571211.22it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1566197.93it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1464460.90it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1469242.82it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1390958.06it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1465189.46it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1325781.80it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1179438.04it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1405196.45it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1374784.81it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1347116.47it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 925385.02it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1439729.98it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1374143.37it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2588637.96it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2137838.46it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1659587.32it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1663251.06it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1553803.55it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1526782.79it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2794273.25it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1985098.29it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1716841.76it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1704736.06it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1660012.51it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1820454.26it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1662482.89it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1727553.14it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1708511.98it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2202965.05it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2307793.42it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1623737.17it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1535611.89it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1534666.23it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1403370.33it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1526423.11it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1463072.04it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1296442.60it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1485614.90it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1008209.76it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2236730.47it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2144347.64it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1569992.93it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1505147.93it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1426606.37it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1290966.49it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1043240.94it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1361038.70it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1398523.81it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1439729.98it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1387918.95it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1370945.12it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1353419.56it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1254717.43it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1267282.28it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1400034.75it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2647879.37it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2299276.37it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1566803.89it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1636119.59it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1537433.76it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1478495.99it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2256516.27it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1692799.88it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1740453.64it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1539259.95it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1623330.37it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1518339.23it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1536850.29it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1473184.67it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1339762.79it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2038047.57it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2088634.14it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1539552.54it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1314965.46it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1209648.42it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1347564.75it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1340039.88it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1228175.15it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1270811.76it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1089444.26it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1246846.17it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2845819.05it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 2698609.25it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1888475.90it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1724885.75it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1808866.78it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1820045.17it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1769543.59it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 891491.58it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1765878.34it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1836449.41it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1688300.80it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1881566.04it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1687509.33it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1873080.72it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1839577.77it/s]\n",
      "100%|██████████| 7724/7724 [00:00<00:00, 1868004.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8h 23min 39s, sys: 1min 37s, total: 8h 25min 17s\n",
      "Wall time: 7h 33min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# #gridsearch doc2vec \n",
    "# sizes = [100,200,300]\n",
    "# windows = [5,10,15,20]\n",
    "# epochs = [5,8,10,15]\n",
    "# summary_list = []\n",
    "\n",
    "# for size in sizes: \n",
    "#     for window in windows: \n",
    "#         for epoch in epochs: \n",
    "#             model_dbow = Doc2Vec(dm=0, \n",
    "#                      vector_size=size, \n",
    "#                      window = window, \n",
    "#                      negative=10, \n",
    "#                      hs=0, \n",
    "#                      min_count=5, \n",
    "#                      sample = 0, \n",
    "#                      workers=cores)\n",
    "        \n",
    "#             model_dbow.build_vocab([x for x in tqdm(train_tagged.values)])\n",
    "\n",
    "#             for epoch in range(epoch):\n",
    "#                 model_dbow.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), \n",
    "#                 total_examples=len(train_tagged.values), epochs=1)\n",
    "#                 model_dbow.alpha -= 0.001\n",
    "#                 model_dbow.min_alpha = model_dbow.alpha\n",
    "    \n",
    "#             y_train, X_train = vec_for_learning(model_dbow, train_tagged)\n",
    "#             y_test, X_test = vec_for_learning(model_dbow, test_tagged)\n",
    "            \n",
    "#             knn = KNeighborsClassifier(n_neighbors= 100)\n",
    "#             knn.fit(X_train, y_train)\n",
    "            \n",
    "#             train_score = knn.score(X_train, y_train)\n",
    "#             test_score = knn.score(X_test, y_test)\n",
    "            \n",
    "#             summary = {}\n",
    "#             summary['size'] = size \n",
    "#             summary['window'] = window \n",
    "#             summary['epoch'] = epoch\n",
    "#             summary['train_score']  = train_score\n",
    "#             summary['test_score'] = test_score\n",
    "            \n",
    "#             summary_list.append(summary)\n",
    "            \n",
    "# summaries_dbow_df = pd.DataFrame(summary_list)\n",
    "# summaries_dbow_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>size</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "      <th>window</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>0.785563</td>\n",
       "      <td>0.807613</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>9</td>\n",
       "      <td>200</td>\n",
       "      <td>0.785563</td>\n",
       "      <td>0.814345</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>0.784657</td>\n",
       "      <td>0.808778</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.784053</td>\n",
       "      <td>0.803470</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>0.784053</td>\n",
       "      <td>0.807354</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>14</td>\n",
       "      <td>300</td>\n",
       "      <td>0.784053</td>\n",
       "      <td>0.816805</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9</td>\n",
       "      <td>200</td>\n",
       "      <td>0.783751</td>\n",
       "      <td>0.811885</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14</td>\n",
       "      <td>100</td>\n",
       "      <td>0.783147</td>\n",
       "      <td>0.811497</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>0.783147</td>\n",
       "      <td>0.813956</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>0.783147</td>\n",
       "      <td>0.803211</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>0.782845</td>\n",
       "      <td>0.812015</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>0.782845</td>\n",
       "      <td>0.807613</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14</td>\n",
       "      <td>100</td>\n",
       "      <td>0.782845</td>\n",
       "      <td>0.808648</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.782543</td>\n",
       "      <td>0.803211</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>14</td>\n",
       "      <td>200</td>\n",
       "      <td>0.782241</td>\n",
       "      <td>0.816157</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14</td>\n",
       "      <td>100</td>\n",
       "      <td>0.782241</td>\n",
       "      <td>0.809684</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>0.781939</td>\n",
       "      <td>0.802305</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>0.781939</td>\n",
       "      <td>0.810590</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>9</td>\n",
       "      <td>300</td>\n",
       "      <td>0.781939</td>\n",
       "      <td>0.817452</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7</td>\n",
       "      <td>200</td>\n",
       "      <td>0.781637</td>\n",
       "      <td>0.807872</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>14</td>\n",
       "      <td>200</td>\n",
       "      <td>0.781637</td>\n",
       "      <td>0.815251</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>14</td>\n",
       "      <td>300</td>\n",
       "      <td>0.781335</td>\n",
       "      <td>0.815251</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>0.781335</td>\n",
       "      <td>0.813827</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>14</td>\n",
       "      <td>300</td>\n",
       "      <td>0.781335</td>\n",
       "      <td>0.815640</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>0.781335</td>\n",
       "      <td>0.806318</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7</td>\n",
       "      <td>200</td>\n",
       "      <td>0.781335</td>\n",
       "      <td>0.809425</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.781033</td>\n",
       "      <td>0.808389</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.781033</td>\n",
       "      <td>0.802563</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>14</td>\n",
       "      <td>200</td>\n",
       "      <td>0.780731</td>\n",
       "      <td>0.812791</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>0.780429</td>\n",
       "      <td>0.804635</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>100</td>\n",
       "      <td>0.780429</td>\n",
       "      <td>0.815122</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>7</td>\n",
       "      <td>300</td>\n",
       "      <td>0.780127</td>\n",
       "      <td>0.814215</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>9</td>\n",
       "      <td>300</td>\n",
       "      <td>0.779825</td>\n",
       "      <td>0.811885</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>0.778919</td>\n",
       "      <td>0.805671</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7</td>\n",
       "      <td>200</td>\n",
       "      <td>0.778919</td>\n",
       "      <td>0.804117</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9</td>\n",
       "      <td>200</td>\n",
       "      <td>0.778919</td>\n",
       "      <td>0.812532</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>7</td>\n",
       "      <td>300</td>\n",
       "      <td>0.778919</td>\n",
       "      <td>0.812273</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>0.778617</td>\n",
       "      <td>0.808907</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>14</td>\n",
       "      <td>300</td>\n",
       "      <td>0.778617</td>\n",
       "      <td>0.816287</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7</td>\n",
       "      <td>200</td>\n",
       "      <td>0.778315</td>\n",
       "      <td>0.810461</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>0.777711</td>\n",
       "      <td>0.802822</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>9</td>\n",
       "      <td>200</td>\n",
       "      <td>0.777711</td>\n",
       "      <td>0.811108</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>14</td>\n",
       "      <td>200</td>\n",
       "      <td>0.777409</td>\n",
       "      <td>0.814474</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>0.777107</td>\n",
       "      <td>0.805541</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>7</td>\n",
       "      <td>300</td>\n",
       "      <td>0.775899</td>\n",
       "      <td>0.808519</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>7</td>\n",
       "      <td>300</td>\n",
       "      <td>0.774690</td>\n",
       "      <td>0.811367</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>9</td>\n",
       "      <td>300</td>\n",
       "      <td>0.774388</td>\n",
       "      <td>0.813050</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>9</td>\n",
       "      <td>300</td>\n",
       "      <td>0.773784</td>\n",
       "      <td>0.815769</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  size  test_score  train_score  window\n",
       "9       7   100    0.785563     0.807613      15\n",
       "26      9   200    0.785563     0.814345      15\n",
       "13      7   100    0.784657     0.808778      20\n",
       "0       4   100    0.784053     0.803470       5\n",
       "36      4   300    0.784053     0.807354      10\n",
       "47     14   300    0.784053     0.816805      20\n",
       "22      9   200    0.783751     0.811885      10\n",
       "7      14   100    0.783147     0.811497      10\n",
       "10      9   100    0.783147     0.813956      15\n",
       "16      4   200    0.783147     0.803211       5\n",
       "2       9   100    0.782845     0.812015       5\n",
       "5       7   100    0.782845     0.807613      10\n",
       "11     14   100    0.782845     0.808648      15\n",
       "4       4   100    0.782543     0.803211      10\n",
       "23     14   200    0.782241     0.816157      10\n",
       "15     14   100    0.782241     0.809684      20\n",
       "20      4   200    0.781939     0.802305      10\n",
       "6       9   100    0.781939     0.810590      10\n",
       "46      9   300    0.781939     0.817452      20\n",
       "29      7   200    0.781637     0.807872      20\n",
       "31     14   200    0.781637     0.815251      20\n",
       "43     14   300    0.781335     0.815251      15\n",
       "14      9   100    0.781335     0.813827      20\n",
       "35     14   300    0.781335     0.815640       5\n",
       "1       7   100    0.781335     0.806318       5\n",
       "25      7   200    0.781335     0.809425      15\n",
       "12      4   100    0.781033     0.808389      20\n",
       "8       4   100    0.781033     0.802563      15\n",
       "27     14   200    0.780731     0.812791      15\n",
       "28      4   200    0.780429     0.804635      20\n",
       "3      14   100    0.780429     0.815122       5\n",
       "45      7   300    0.780127     0.814215      20\n",
       "34      9   300    0.779825     0.811885       5\n",
       "40      4   300    0.778919     0.805671      15\n",
       "21      7   200    0.778919     0.804117      10\n",
       "18      9   200    0.778919     0.812532       5\n",
       "41      7   300    0.778919     0.812273      15\n",
       "32      4   300    0.778617     0.808907       5\n",
       "39     14   300    0.778617     0.816287      10\n",
       "17      7   200    0.778315     0.810461       5\n",
       "24      4   200    0.777711     0.802822      15\n",
       "30      9   200    0.777711     0.811108      20\n",
       "19     14   200    0.777409     0.814474       5\n",
       "44      4   300    0.777107     0.805541      20\n",
       "33      7   300    0.775899     0.808519       5\n",
       "37      7   300    0.774690     0.811367      10\n",
       "38      9   300    0.774388     0.813050      10\n",
       "42      9   300    0.773784     0.815769      15"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries_dbow_df.sort_values(by = ['test_score'], ascending= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
